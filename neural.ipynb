{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "endless-couple",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import pathlib\n",
    "import re\n",
    "import string\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import preprocessing\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_text as tf_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "pleased-candle",
   "metadata": {},
   "outputs": [],
   "source": [
    "from grabber import ChatBoxGrabber\n",
    "dataset = []\n",
    "for key, data in pickle.load(open('data.pickle', 'rb')).items():\n",
    "    dataset.append(tuple([data.message, data.user]))\n",
    "random.shuffle(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "technological-marks",
   "metadata": {},
   "outputs": [],
   "source": [
    "for user in {pair[1] for pair in dataset}:\n",
    "    if sum([True for pair in dataset if pair[1] == user]) < 2000:\n",
    "        dataset = [pair for pair in dataset if not user == pair[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "instructional-execution",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = [pair for pair in dataset if len(pair[0]) < 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "opposite-class",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [pair[0] for pair in dataset]\n",
    "senders = [pair[1] for pair in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "seven-diabetes",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {'':0}\n",
    "for message in messages:\n",
    "    for char in message:\n",
    "        if char not in vocab.keys():\n",
    "            vocab[char] = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "waiting-white",
   "metadata": {},
   "outputs": [],
   "source": [
    "userVocab = {}\n",
    "for user in senders:\n",
    "    if user not in userVocab.keys():\n",
    "            userVocab[user] = len(userVocab)\n",
    "senders = [userVocab[user] for user in senders]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "convenient-seating",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(string):\n",
    "    if not type(string) == str:\n",
    "        return [vectorize(str) for str in string]\n",
    "    ans=np.zeros(100, dtype = int)\n",
    "    for i in range(len(string)):\n",
    "        ans[i] = vocab[string[i]]\n",
    "    return ans\n",
    "#vectorize(messages[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "prime-triangle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105886, 100)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = np.array([vectorize(message) for message in messages])\n",
    "#dataframe = pd.DataFrame({'x':messages, 'y':senders}).sample(frac=1).reset_index(drop=True)\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "coral-unknown",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = tf.data.Dataset.from_tensor_slices((vectors[:10000], senders[:10000]))\n",
    "validate = tf.data.Dataset.from_tensor_slices((vectors[10000:30000], senders[10000:30000]))\n",
    "train = tf.data.Dataset.from_tensor_slices((vectors[30000:], senders[30000:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "caring-crossing",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((messages, np.array(senders)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ecological-capability",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "      layers.Embedding(len(vocab), 64, mask_zero=True),\n",
    "      layers.Conv1D(64, 5, padding=\"valid\", activation=\"relu\", strides=2),\n",
    "      layers.Conv1D(64, 5, padding=\"valid\", activation=\"relu\", strides=2),\n",
    "      layers.Conv1D(64, 5, padding=\"valid\", activation=\"relu\", strides=2),\n",
    "      layers.Conv1D(64, 5, padding=\"valid\", activation=\"relu\", strides=2),\n",
    "      layers.GlobalMaxPooling1D(),\n",
    "      layers.Dense(len({i for i in senders}))\n",
    "  ])\n",
    "model.compile(\n",
    "    loss=losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "permanent-finish",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset shapes: ((100,), ()), types: (tf.int32, tf.int32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "studied-center",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2372/2372 [==============================] - 14s 6ms/step - loss: 2.1907 - accuracy: 0.2420\n",
      "Epoch 2/50\n",
      "2372/2372 [==============================] - 15s 6ms/step - loss: 1.8411 - accuracy: 0.3660\n",
      "Epoch 3/50\n",
      "2372/2372 [==============================] - 17s 7ms/step - loss: 1.7423 - accuracy: 0.3998\n",
      "Epoch 4/50\n",
      "2372/2372 [==============================] - 17s 7ms/step - loss: 1.6765 - accuracy: 0.4209\n",
      "Epoch 5/50\n",
      "2372/2372 [==============================] - 17s 7ms/step - loss: 1.6322 - accuracy: 0.4358\n",
      "Epoch 6/50\n",
      "2372/2372 [==============================] - 17s 7ms/step - loss: 1.5791 - accuracy: 0.4568\n",
      "Epoch 7/50\n",
      "2372/2372 [==============================] - 16s 7ms/step - loss: 1.5352 - accuracy: 0.4698\n",
      "Epoch 8/50\n",
      "2372/2372 [==============================] - 15s 7ms/step - loss: 1.4998 - accuracy: 0.4847\n",
      "Epoch 9/50\n",
      "2372/2372 [==============================] - 17s 7ms/step - loss: 1.4611 - accuracy: 0.5004\n",
      "Epoch 10/50\n",
      "2372/2372 [==============================] - 18s 7ms/step - loss: 1.4367 - accuracy: 0.5073\n",
      "Epoch 11/50\n",
      "2372/2372 [==============================] - 18s 7ms/step - loss: 1.3881 - accuracy: 0.5261\n",
      "Epoch 12/50\n",
      "2372/2372 [==============================] - 18s 7ms/step - loss: 1.3608 - accuracy: 0.5321\n",
      "Epoch 13/50\n",
      "2372/2372 [==============================] - 18s 8ms/step - loss: 1.3349 - accuracy: 0.5411\n",
      "Epoch 14/50\n",
      "2372/2372 [==============================] - 17s 7ms/step - loss: 1.3113 - accuracy: 0.5522\n",
      "Epoch 15/50\n",
      "2372/2372 [==============================] - 17s 7ms/step - loss: 1.2851 - accuracy: 0.5588\n",
      "Epoch 16/50\n",
      "2372/2372 [==============================] - 19s 8ms/step - loss: 1.2635 - accuracy: 0.5670\n",
      "Epoch 17/50\n",
      "2372/2372 [==============================] - 18s 8ms/step - loss: 1.2428 - accuracy: 0.5733\n",
      "Epoch 18/50\n",
      "2372/2372 [==============================] - 19s 8ms/step - loss: 1.2159 - accuracy: 0.5817\n",
      "Epoch 19/50\n",
      "2372/2372 [==============================] - 18s 8ms/step - loss: 1.1933 - accuracy: 0.5917\n",
      "Epoch 20/50\n",
      "2372/2372 [==============================] - 18s 7ms/step - loss: 1.1808 - accuracy: 0.5952\n",
      "Epoch 21/50\n",
      "2372/2372 [==============================] - 18s 8ms/step - loss: 1.1574 - accuracy: 0.6034\n",
      "Epoch 22/50\n",
      "2372/2372 [==============================] - 18s 7ms/step - loss: 1.1431 - accuracy: 0.6098\n",
      "Epoch 23/50\n",
      "2372/2372 [==============================] - 18s 7ms/step - loss: 1.1389 - accuracy: 0.6088\n",
      "Epoch 24/50\n",
      "2372/2372 [==============================] - 18s 7ms/step - loss: 1.1219 - accuracy: 0.6158\n",
      "Epoch 25/50\n",
      "2372/2372 [==============================] - 18s 7ms/step - loss: 1.1010 - accuracy: 0.6223\n",
      "Epoch 26/50\n",
      "2372/2372 [==============================] - 18s 8ms/step - loss: 1.0880 - accuracy: 0.6270\n",
      "Epoch 27/50\n",
      "2372/2372 [==============================] - 18s 8ms/step - loss: 1.0731 - accuracy: 0.6307\n",
      "Epoch 28/50\n",
      "2372/2372 [==============================] - 18s 8ms/step - loss: 1.0686 - accuracy: 0.6357\n",
      "Epoch 29/50\n",
      "2372/2372 [==============================] - 18s 8ms/step - loss: 1.0604 - accuracy: 0.6369\n",
      "Epoch 30/50\n",
      "2372/2372 [==============================] - 18s 8ms/step - loss: 1.0554 - accuracy: 0.6392\n",
      "Epoch 31/50\n",
      "2372/2372 [==============================] - 18s 8ms/step - loss: 1.0324 - accuracy: 0.6472\n",
      "Epoch 32/50\n",
      "2372/2372 [==============================] - 18s 8ms/step - loss: 1.0304 - accuracy: 0.6465\n",
      "Epoch 33/50\n",
      "2372/2372 [==============================] - 18s 8ms/step - loss: 1.0200 - accuracy: 0.6506\n",
      "Epoch 34/50\n",
      "2372/2372 [==============================] - 18s 8ms/step - loss: 1.0076 - accuracy: 0.6508\n",
      "Epoch 35/50\n",
      "2372/2372 [==============================] - 18s 8ms/step - loss: 1.0050 - accuracy: 0.6555\n",
      "Epoch 36/50\n",
      "2372/2372 [==============================] - 18s 7ms/step - loss: 0.9954 - accuracy: 0.6578\n",
      "Epoch 37/50\n",
      "2372/2372 [==============================] - 19s 8ms/step - loss: 0.9825 - accuracy: 0.6612\n",
      "Epoch 38/50\n",
      "2372/2372 [==============================] - 18s 8ms/step - loss: 0.9821 - accuracy: 0.6633\n",
      "Epoch 39/50\n",
      "2372/2372 [==============================] - 18s 8ms/step - loss: 0.9709 - accuracy: 0.6681\n",
      "Epoch 40/50\n",
      "2372/2372 [==============================] - 18s 8ms/step - loss: 0.9683 - accuracy: 0.6666\n",
      "Epoch 41/50\n",
      "2372/2372 [==============================] - 19s 8ms/step - loss: 0.9639 - accuracy: 0.6694\n",
      "Epoch 42/50\n",
      "2372/2372 [==============================] - 19s 8ms/step - loss: 0.9571 - accuracy: 0.6702\n",
      "Epoch 43/50\n",
      "2372/2372 [==============================] - 23s 10ms/step - loss: 0.9510 - accuracy: 0.6745\n",
      "Epoch 44/50\n",
      "2372/2372 [==============================] - 19s 8ms/step - loss: 0.9472 - accuracy: 0.6743\n",
      "Epoch 45/50\n",
      "2372/2372 [==============================] - 21s 9ms/step - loss: 0.9351 - accuracy: 0.6782\n",
      "Epoch 46/50\n",
      "2372/2372 [==============================] - 20s 8ms/step - loss: 0.9362 - accuracy: 0.6781\n",
      "Epoch 47/50\n",
      "2372/2372 [==============================] - 20s 8ms/step - loss: 0.9268 - accuracy: 0.6815\n",
      "Epoch 48/50\n",
      "2372/2372 [==============================] - 20s 8ms/step - loss: 0.9207 - accuracy: 0.6827\n",
      "Epoch 49/50\n",
      "2372/2372 [==============================] - 20s 9ms/step - loss: 0.9173 - accuracy: 0.6819\n",
      "Epoch 50/50\n",
      "2372/2372 [==============================] - 19s 8ms/step - loss: 0.9100 - accuracy: 0.6873\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2863fa6b9d0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(vectors[30000:].tolist(), senders[30000:], epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "seven-winning",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "max() arg is an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-5b198bfd9915>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mtemp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0muser\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvects\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: max() arg is an empty sequence"
     ]
    }
   ],
   "source": [
    "val = []\n",
    "for user in userVocab.values():\n",
    "    vects = []\n",
    "    for i in range(len(senders)):\n",
    "        if(senders[i] == user):\n",
    "            vects.append(vectors[i])\n",
    "    temp = sum(model.predict(np.array(random.sample(vects, 10))))\n",
    "    print(max(temp) == temp[user])\n",
    "    if not max(temp) == temp[user]:\n",
    "        val.append(len(vects))\n",
    "max(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "proper-wrestling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101237\r"
     ]
    }
   ],
   "source": [
    "lil = [messages[i] for i in range(len(senders)) if print(i, end=\"\\r\") or senders[i] == userVocab[2903]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "severe-bearing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15230\n"
     ]
    }
   ],
   "source": [
    "print(len(lil))\n",
    "lilPres = [predicts[userVocab[2903]] for predicts in model.predict(np.array(vectorize(lil)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "grateful-setting",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(15.597538, 'قیمت اون سه تا دونه عینک بابام: قیمت نهایی: ۱,۰۳۹,۴۰۰ تومان'),\n",
       " (15.712978, 'اما همه ی اسرارتو باید بریزی رو داریه.دایره.درایه.حالا هرچی!!!'),\n",
       " (15.8894205,\n",
       "  '@Louis وگرنه من سوپرمن،فلش،جوکر،هارلی،آکوامن...همه ی اینا رو دوست دارم'),\n",
       " (15.973396,\n",
       "  '*با تلفن حرف زدن*نه نه...ناپلئونی دوست ندارم....زبون؟نه....نون خامه ای؟آره....به اندازه باشه.....ببین من آبرو دارما!واسه خودمم یه کیلو کیک برونی بزار کنار میام میبرم....خدافظ'),\n",
       " (16.424473,\n",
       "  '@شرلوک\\u200cهلمز پس خیلات راحت.این کرونا نیست......پس به من بدین نمره ی بیست!:21:'),\n",
       " (16.807104,\n",
       "  '*از خواب پریدن*میستری!میستری زنده ست!تو جهنمه!میتونیم برش گردونیم!'),\n",
       " (17.057531, '@DarkGuy چچه؟!*اکسیو یخچال**وینگاردیم لویوسا**دیفندو*'),\n",
       " (17.378464,\n",
       "  '@DarkGuy ریموس لوپین،نیمفادورا تانکس،سیریوس بلک،الستور مودی،فرد ویزلی و خیلیای دیگه نباید می مردن'),\n",
       " (18.445826, '*نعره زدن*هموند!بسه!اینقدر گاز نده!'),\n",
       " (18.524721, 'من،جان ویک،جان سینا،ترمیناتور،ویل مارکس')]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lilPairs = [(lilPres[i], lil[i]) for i in range(len(lil))]\n",
    "lilPairs.sort()\n",
    "lilPairs[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "joint-thunder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 3, 5, 6, 7, 10, 12]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in range(15) if model.predict(np.array(vectorize([\"بچه ها\"])))[0][i] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "moderate-questionnaire",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([2274, 3074, 1034, 2903, 986, 635, 1714, 2803, 2905, 2914, 2454, 2883, 321])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "userVocab.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "automatic-tribune",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2777"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter = 0\n",
    "for i in range(0, len(senders)):\n",
    "        if(senders[i] == 3):\n",
    "            counter +=1\n",
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "macro-packaging",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.259055  , -1.9234855 ,  3.8764307 ,  2.1480486 ,  4.610029  ,\n",
       "        1.1548915 , -0.19314751,  1.8464661 ,  5.452761  ,  1.2430861 ,\n",
       "        0.9013407 , -0.1955685 , -4.0964465 ], dtype=float32)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(np.array([vectorize(\"@شرلوک‌هلمز اسمش چیه؟\")]))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "actual-transmission",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  2240.3018,  -5910.2153,   3454.702 ,  -4566.301 , -11807.172 ,\n",
       "       -10405.755 , -10313.312 ,  -6268.75  ,    845.2459,  -4315.7764,\n",
       "        -7612.003 , -13785.518 ,  -4810.502 ], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(model.predict(np.array([vectorize(messages[i]) for i in range(30000) if senders[i] == 2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "opened-ordering",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([senders[i]==594 for i in range(30000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "silent-correlation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1546"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([True for pair in dataset if pair[1] == 2507])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
